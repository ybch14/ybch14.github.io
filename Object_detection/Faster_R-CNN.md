# Faster R-CNN

Fast R-CNN 的扩展。R-CNN、SPPnet、Fast R-CNN 都是先用 Selective Search 选择候选框，然后送入卷积层/映射到卷积层输出的特征图。Faster R-CNN 提出 Region Proposal Network (RPN) 来提取候选框。首先用卷积网络（VGG / ZF）提取特征图，然后用 RPN 对特征图提取候选框，再把候选框和特征图送入 Fast R-CNN。

### 1. Region Proposal Networks  

- 用小的全卷积网络（简称小网络）在卷积网络最后一层输出的特征图上滑动。小网络的输入是 $n \times n$ 的特征图窗口。每个窗口通过小网络后输出为一个低维度的向量（256 或 512， 激活函数为 ReLU）。输出的向量经过两个全连接得到 box regression 和 classification 输出。通常取 $n = 3$，因为最后一层特征图上的窗口映射到原始图片上会对应一个非常大的感受野。为了让所有的窗口共享全连接层的参数，小网络的全连接层用 $1 \times 1$ 的卷积层实现。

- Anchors

  - 在每个（特征图上的）滑动窗口的位置可以预测得到多个候选框。记每个位置能够预测产生候选框的最大数量为 $k$ 。则在每个位置小网络的输出都有 $4k$ 个边框向量和 $2k$ 个分类输出（只考虑2分类）。这 $k$ 个特征图上的候选框分别对应原图片上 k 个候选框。称在原图上的候选框为 anchors 。一个 anchor 的中心与（原图像上的）滑动窗口的中心位置重合，包含多个尺度和多种长宽比。默认参数为 $k = 9$ ，3 种尺度，3 种长宽比。如果特征图尺度为 $W\times H$ ，则一共有 $WHk$ 个 anchors。
  - Anchor 具有平移不变性，因为小网络是一个全卷积网络（？）。平移不变性还使得模型参数减少，更容易训练。
  - Anchors 具有多种尺度和多种长宽比，使得 RPN 能够处理多尺度下的图片数据，避免了对同一张图片的不同尺度的副本进行反复计算的冗余性。而且网络的卷积核可以采用单个参数，降低训练难度。
  - 这种多尺度的设计方法使得某一张图片只需要经过一次卷积网络，节省时间。

- 训练细节

  - 为了训练 RPN ，需要对每个 anchor 标记正或负样本。如果（1）某一个 anchor 与 ground truth 框的交并比最高，或者（2）某一个 anchor 和 ground truth 框的交并比大于 **0.7** ，则该 anchor 为正样本；如果某一个 anchor 和 ground truth 框的交并比小于 **0.3** ，则该 anchor 为负样本。除了这两者之外的候选框不参与训练。

  - 损失函数的表达式如下：

    $$L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}}\sum_iL_{cls}(p_i, p_i^*) + \lambda\frac{1}{N_{reg}}\sum_ip_i^*L_{reg}(t_i, t_i^*)$$ 

    i 是 anchor 在一个batch中的编号，$p_i$ 是第 i 个 anchor 为物体的预测概率，$p_i^*$ 是第 i 个 anchor 为物体的真实概率（正样本为1，负样本为0，即负样本不贡献回归损失）。$t_i$ 是预测输出的参数化的 box regression 向量（同 Fast R-CNN 的参数化方法），$t_i^*$ 是真实的参数化的 box regression 向量。$L_{cls}$ 是对数损失函数，$L_{reg}$ 是 smooth L1 损失函数。

  - 损失函数的两个分量分别被 $N_{cls}$ （论文中取256）和 $N_{reg}$ （通常为2400）归一化。$\lambda$ 是平衡分类和回归结果的超参数，由上面两个归一化系数的值可以选择 $\lambda = 10$ 。

  - 在进行 box regression 的时候有一个细节：不是所有的 anchor 共享一个 regressor，而是每个尺度和每个长宽比的 anchor 都有一个独立的 regressor，权值不共享。

- 训练

  - 如果把图片中所有正负样本的 anchor 都用来训练，那么训练数据中负样本的比重会很大，对训练不好。
  - 对每张图片采样得到 256 个训练 anchor，其中正负样本比例接近 1：1。如果正样本不够128个，用负样本补齐。
  - 卷积网络初始化用在 ImageNet 上预训练得到的参数（VGG / ZF）。新层用零均值/方差0.01的高斯分布初始化。

### 2. RPN 和 Fast R-CNN 共享特征图

- RPN 和 Fast R-CNN 分别训练会使得两个网络协同工作的效果不好。
- 交换训练：第一步先用上述方法训练 RPN；第二步用刚才训练好的 RPN 生成的候选框训练 Fast R-CNN；第三步用上一步训练好的 Fast R-CNN 里面的卷积网络的参数来对 RPN 的训练进行初始化，只微调专属于 RPN 的层（在这一步两个网络共享卷积网络参数）；最后一步保持共享的卷积层参数不变，只微调专属于 Fast R-CNN 的层。经过上述步骤之后两个网络可以合并成一个统一的网络架构。


### 3. 实现细节

- 图片缩放到较短的边为600像素。
- anchor 有 9 种，面积为 $128^2, 256^2, 512^2$ ，长宽比为 $1:1,\  1:2,\  2:1$ 。
- 和图片边缘有交叉的 anchor 需要格外注意。论文里的处理方法是把和边界有交叉的 anchor 忽略。对于典型的 $1000 \times 600$ 的图片，总共大概有 20000 个 anchor，去掉和边界交叉的之后剩下大概 6000 个。如果不忽略，训练不收敛。
- RPN 生成的候选框可能有大量的重叠框。解决方法是 NMS（NMS中候选框的置信度为RPN输出的cls分数）。NMS 的 IoU 阈值为 0.7。经过筛选之后得到大概 2000 个候选框。


### 4. 实验结果

- VOC 2012 结果

|      method       | \# proposals |    data     |   mAP    |
| :---------------: | :----------: | :---------: | :------: |
|        SS         |     2000     |   07++12    |   68.4   |
| RPN + VGG, shared |     300      |   07++12    | **70.4** |
| RPN + VGG, shared |     300      | COCO+07++12 | **75.9** |

- 速度比较

| model |      system      | time/ms |  rate  |
| :---: | :--------------: | :-----: | :----: |
|  VGG  | SS + Fast R-CNN  |  1830   | 0.5fps |
|  VGG  | RPN + Fast R-CNN |   198   |  5fps  |
|  ZF   | RPN + Fast R-CNN |   59    | 17fps  |

RPN 有效提高系统运行速度。

- anchors 选择

|      settings      |        anchor scales        |  aspect ratios  |   mAP    |
| :----------------: | :-------------------------: | :-------------: | :------: |
|  1 scale, 1 ratio  |           256$^2$           |       1:1       |   66.7   |
| 1 scale, 3 ratios  |           256$^2$           | {2:1, 1:1, 1:2} |   67.9   |
| 3 scales, 1 ratio  | {128$^2$, 256$^2$, 512$^2$} |       1:1       | **69.8** |
| 3 scales, 3 ratios | {128$^2$, 256$^2$, 512$^2$} | {2:1, 1:1, 1:2} | **69.9** |

- $\lambda$ 选择

| $\lambda$ | 0.1  |  1   |  10  | 100  |
| :-------: | :--: | :--: | :--: | :--: |
|    mAP    | 67.2 | 68.9 | 69.9 | 69.1 |



###### 参考文献 

###### 1. S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In NIPS, 2015